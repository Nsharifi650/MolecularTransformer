{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "file_handler = logging.FileHandler('Logs.log')\n",
    "console_handler = logging.StreamHandler()\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "console_handler.setLevel(logging.ERROR)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s - Line: %(lineno)d', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "# logger.addHandler(console_handler)\n",
    "\n",
    "logger.debug(\"This is a debug message\")\n",
    "logger.info(\"This is an info message\")\n",
    "logger.warning(\"This is a warning message\")\n",
    "logger.error(\"This is an error message\")\n",
    "logger.critical(\"This is a critical message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIHEAD ATTENTION \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        try:\n",
    "            assert d_model % num_heads == 0\n",
    "        except Exception as e:\n",
    "            logger.error(\"dimension of the embedding model is not divisable by number of heads\")\n",
    "        \n",
    "        self.d_models = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # The query, key, value learnable matrices\n",
    "        self.Wq = nn.Linear(d_model, d_model)\n",
    "        self.Wk = nn.Linear(d_model, d_model)\n",
    "        self.Wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.FCLayer = nn.Linear(d_model, d_model)\n",
    "    def split_embedding_perHead(self,x):\n",
    "        # x shape is (batch_size, seq_len, d_model)\n",
    "        (batch_size, seq_len, d_model) = x.shape\n",
    "        # logger.info(f\"multi-head; x-shape: {x.shape}\")\n",
    "        # let's reshape to (batch_size, seq_len, num_heads, depth)\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        logger.info(f\"Multi-head; x reshaped: {x.shape} \")\n",
    "        # changing the dimensions order to:(batch_size, num_heads, seq_len, depth)\n",
    "        x = x.permute(0,2,1,3)\n",
    "        return x\n",
    "    \n",
    "    def cal_attention(self,q,k,v,mask):\n",
    "        qk = torch.matmul(q, k.permute(0,1,3,2))\n",
    "        dk=torch.tensor(k.shape[-1], dtype=torch.float32)\n",
    "        #dk is a tensor scalar!\n",
    "        attention = qk/torch.sqrt(dk)\n",
    "\n",
    "        # print(\"CHECKING PADDING MASK CODE\")\n",
    "        # print(\"q shape\", q.shape)\n",
    "        # print(\"attention shape\", attention.shape)\n",
    "        if mask is not None:\n",
    "            attention += (mask*-1e9)\n",
    "        # print(\"attention values after masking\", attention[0,0,:,:])\n",
    "        attention_weights = F.softmax(attention, dim=-1) # should be applied along the sequence which is the 3rd dimension\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "\n",
    "\n",
    "        # print(\"mask\", mask[0,0,:,:])\n",
    "        # print(\"q shape\", q.shape)\n",
    "        # print(\"mask shape\", mask.shape)\n",
    "        # print(\"attention weights shape\", attention_weights.shape)\n",
    "        # print(\"attention weights example\", attention_weights[0,0,:,:])\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def forward(self, v,k,q,mask):\n",
    "        batch_size = q.shape[0]\n",
    "        # shapes for debugging\n",
    "        # print(\"v shape\", v.shape)\n",
    "        # print(\"q shape\", q.shape)\n",
    "        # print(\"k shape\", k.shape)\n",
    "        # print(\"mask shape\", mask.shape)\n",
    "        q = self.split_embedding_perHead(self.Wq(q))\n",
    "        k = self.split_embedding_perHead(self.Wk(k))\n",
    "        v = self.split_embedding_perHead(self.Wv(v))\n",
    "\n",
    "        # print(\"v shape after splitting\", v.shape)\n",
    "        # print(\"q shape after splitting\", q.shape)\n",
    "        # print(\"k shape after splitting\", k.shape)\n",
    "\n",
    "        attention,atten_weights = self.cal_attention(q,k,v,mask)\n",
    "        attention = attention.permute(0,2,1,3).contiguous()\n",
    "        attention = attention.reshape(batch_size, -1, self.d_models)\n",
    "\n",
    "        output = self.FCLayer(attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ENCODER LAYER\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,dff):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.FeedForwardNN = nn.Sequential(\n",
    "            nn.Linear(d_model,dff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dff,dff)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.FeedForwardNN(x)\n",
    "        logger.info(f\"encoder output dimensions {output.shape}\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE DECODER LAYER\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model, num_heads, dff):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.MultiHAttention1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.MultiHAttention2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.FeedForwardNN = nn.Sequential(\n",
    "            nn.Linear(d_model,dff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dff,d_model)\n",
    "\n",
    "        )\n",
    "        self.layerNorm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.layerNorm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.layerNorm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # print(f\"FIRST MHA WITH LOOK AHEAD MASK\")\n",
    "        attn_output1 = self.MultiHAttention1(x,x,x,look_ahead_mask)\n",
    "        attn_output1 = self.layerNorm1(x+attn_output1)\n",
    "        # print(f\"decoder input into second multihead attention layer:{attn_output1.shape}\")\n",
    "        attn_output2 = self.MultiHAttention2(enc_output, enc_output,attn_output1, padding_mask)\n",
    "        attn_output2 = self.layerNorm2(attn_output2+attn_output1)\n",
    "\n",
    "        Feedforward_output = self.FeedForwardNN(attn_output2)\n",
    "        final_output = self.layerNorm3(attn_output2+Feedforward_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(target_vocab_size, d_model) # d_model is the size of embedding vector\n",
    "        self.pos_encoding = self.positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, dff) for _ in range(num_layers)])\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return torch.tensor(pos_encoding, dtype=torch.float32)\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(1000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        logger.info(f\"decoder input shape to the embedding: {x.shape}\")\n",
    "        seq_len = x.size(1)\n",
    "        x = self.embedding(x)\n",
    "        logger.info(f\"decoder input shape after embedding: {x.shape}\")\n",
    "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "\n",
    "        logger.info(f\"final decoder output shape {x.shape}\")\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMER\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,num_layers, enc_d_model, dec_d_model,\n",
    "                enc_num_heads, dec_num_heads, enc_dff, \n",
    "                dec_dff, target_vocab_size, pe_target):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
    "        self.encoder = EncoderLayer(enc_d_model, enc_dff)\n",
    "        self.decoder = Decoder(num_layers, dec_d_model, dec_num_heads, dec_dff, target_vocab_size, pe_target)\n",
    "        self.final_layer = nn.Linear(dec_d_model, target_vocab_size)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, properties, target, look_ahead_mask, dec_padding_mask, training):\n",
    "        logger.info(\"ENCODER STARTED\")\n",
    "        enc_output = self.encoder(properties)\n",
    "        logger.info(\"ENCODER COMPLETED\")\n",
    "        # currently the encoder output will be [batch_size, 1, d_model] i.e. sequence of size 1\n",
    "        # to ensure it is compatable with the decoder MHA first layer, \n",
    "        # we need to expand sequence length to same length as target\n",
    "        enc_output_reshaped = enc_output.unsqueeze(1).repeat(1, target.shape[1],1)\n",
    "        logger.info(f\"encoder output dimensions:{enc_output.shape}\")\n",
    "        logger.info(f\"encoder output reshaped: {enc_output_reshaped.shape}\")\n",
    "        logger.info(\"DECODER STARTED\")\n",
    "\n",
    "        dec_output = self.decoder(target, enc_output_reshaped, look_ahead_mask, dec_padding_mask)\n",
    "        ffl_output = self.final_layer(dec_output)\n",
    "\n",
    "        #####during training:\n",
    "        if training:\n",
    "            return ffl_output\n",
    "        \n",
    "        else:\n",
    "\n",
    "        ##### During inference::\n",
    "        # # the ffl output is is of shape [batch, seq_len, target_vocab_size]\n",
    "        # # the last dimension will need to be passed through a softmax to determine \n",
    "        # # the most likely token\n",
    "            # print(\"transformer output logits: \", ffl_output.shape)\n",
    "            probabilities = F.softmax(ffl_output, dim=-1)\n",
    "            # print(\"probabilities: \", probabilities.shape)\n",
    "            # To get the predicted tokens\n",
    "            predicted_tokens = torch.argmax(probabilities, dim=-1)\n",
    "            # print(\"final token\", predicted_tokens.shape)\n",
    "            return predicted_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of smiles:  (5837,)\n",
      "{'#': 3, '%': 4, '(': 5, ')': 6, '+': 7, '-': 8, '.': 9, '/': 10, '0': 11, '1': 12, '2': 13, '3': 14, '4': 15, '5': 16, '6': 17, '7': 18, '8': 19, '9': 20, '=': 21, '@': 22, 'A': 23, 'B': 24, 'C': 25, 'F': 26, 'G': 27, 'H': 28, 'I': 29, 'K': 30, 'L': 31, 'M': 32, 'N': 33, 'O': 34, 'P': 35, 'R': 36, 'S': 37, 'T': 38, 'U': 39, 'V': 40, 'W': 41, 'Y': 42, 'Z': 43, '[': 44, '\\\\': 45, ']': 46, 'a': 47, 'b': 48, 'c': 49, 'd': 50, 'e': 51, 'f': 52, 'g': 53, 'h': 54, 'i': 55, 'l': 56, 'm': 57, 'n': 58, 'o': 59, 'p': 60, 'r': 61, 's': 62, 't': 63, 'u': 64, '<pad>': 0, '<start>': 1, '<end>': 2}\n",
      "max smiles length:  428\n",
      "smiles length: 5837\n",
      "smiles example:  [1, 25, 25, 5, 25, 33, 6, 34, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "smiles example length:  428\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, properties, smiles):\n",
    "        self.properties = properties\n",
    "        self.smiles = smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.properties)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.properties[idx], dtype=torch.float32), torch.tensor(self.smiles[idx], dtype=torch.long)\n",
    "\n",
    "\n",
    "def preprocess_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    properties = data[['polararea', 'complexity', 'heavycnt', 'hbonddonor', 'hbondacc']].values\n",
    "    smiles = data['isosmiles'].values\n",
    "    print(\"length of smiles: \", smiles.shape)\n",
    "    # print(f\"smiles: {smiles}\")\n",
    "\n",
    "    # print(f\"properties: {properties}\")\n",
    "    \n",
    "    # Normalize properties\n",
    "    scaler = StandardScaler()\n",
    "    properties = scaler.fit_transform(properties)\n",
    "    \n",
    "    # Convert SMILES to a list of character indices\n",
    "    # only unique characters remain\n",
    "    # this is for creating a vocab to use to enumerate the smiles notation\n",
    "    char_to_idx = {char: idx + 3 for idx, char in enumerate(sorted(set(''.join(smiles))))}\n",
    "    char_to_idx['<pad>'] = 0\n",
    "    char_to_idx['<start>'] = 1\n",
    "    char_to_idx['<end>'] = 2\n",
    "\n",
    "    print(char_to_idx)\n",
    "    # reversing the index to character\n",
    "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "    \n",
    "    max_smiles_len = max(len(s) for s in smiles)+2 # 2 for the start and end token\n",
    "    print(\"max smiles length: \", max_smiles_len)\n",
    "    smiles_indices = [\n",
    "        [char_to_idx['<start>']] + [char_to_idx[char] for char in smi] + [char_to_idx['<end>']] + \n",
    "        [char_to_idx['<pad>']] * (max_smiles_len - len(smi) - 2)\n",
    "        for smi in smiles\n",
    "    ]\n",
    "\n",
    "    # testing the smiles indices code\n",
    "    print(\"smiles length:\",len(smiles_indices))\n",
    "    for smile_i in smiles_indices:\n",
    "        print(\"smiles example: \", smile_i)\n",
    "        print(\"smiles example length: \", len(smile_i))\n",
    "        break\n",
    "\n",
    "    return properties, smiles_indices, char_to_idx, idx_to_char, scaler\n",
    "\n",
    "properties, smiles_indices, char_to_idx, idx_to_char, scaler = preprocess_data('Pubchem.csv')\n",
    "\n",
    "train_props, test_props, train_smiles, test_smiles = train_test_split(properties, smiles_indices, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = MoleculeDataset(train_props, train_smiles)\n",
    "test_dataset = MoleculeDataset(test_props, test_smiles)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq_masked = torch.tensor(seq) == 0 # True if value is 0 otherwise false\n",
    "    return seq_masked.unsqueeze(1).unsqueeze(2) \n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    # creating an upper triangle of 1s\n",
    "    mask = torch.triu(torch.ones((size, size)), diagonal=1) \n",
    "    return mask.unsqueeze(0).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target vocab size 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NajibS\\AppData\\Local\\Temp\\ipykernel_23776\\2541678855.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seq_masked = torch.tensor(seq) == 0 # True if value is 0 otherwise false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 427])\n",
      "mask tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]])\n",
      "loss matrix shape torch.Size([128, 427])\n",
      "loss before mask tensor([[3.0243, 2.9710, 2.9058,  ..., 5.2769, 5.2613, 5.2606],\n",
      "        [3.0127, 2.9446, 5.2871,  ..., 5.2812, 5.2549, 5.2565],\n",
      "        [3.8507, 3.8995, 3.8329,  ..., 5.0689, 5.0178, 5.0160],\n",
      "        ...,\n",
      "        [2.9445, 2.9005, 2.8404,  ..., 5.0931, 5.0569, 5.0612],\n",
      "        [3.0088, 2.9600, 2.9053,  ..., 5.2361, 5.2085, 5.2071],\n",
      "        [3.0509, 5.2522, 2.5496,  ..., 5.1318, 5.1166, 5.1157]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "loss after mask tensor([[3.0243, 2.9710, 2.9058,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [3.0127, 2.9446, 5.2871,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [3.8507, 3.8995, 3.8329,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [2.9445, 2.9005, 2.8404,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [3.0088, 2.9600, 2.9053,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [3.0509, 5.2522, 2.5496,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<AsStridedBackward0>)\n",
      "batch loss 0.23208722472190857\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 101\u001b[0m\n\u001b[0;32m     98\u001b[0m transformer \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[107], line 61\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(transformer, train_loader, num_epochs, learning_rate, model_name, pretrained)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# print(\"look ahead mask shape\", look_ahead_mask.shape)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# print(\"padding mask shape\", dec_padding_mask.shape)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# print(\"look ahead mask: \", look_ahead_mask)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# print(\"padding mask\", dec_padding_mask)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 61\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# print(\"predictions\", predictions.shape)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# print(\"smiles: \", smiles.shape)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(smiles[:, \u001b[38;5;241m1\u001b[39m:], predictions[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[101], line 28\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, properties, target, look_ahead_mask, dec_padding_mask, training)\u001b[0m\n\u001b[0;32m     25\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder output reshaped: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menc_output_reshaped\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDECODER STARTED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m ffl_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(dec_output)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#####during training:\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[100], line 33\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, enc_output, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding[:, :seq_len, :]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m---> 33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal decoder output shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[99], line 22\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[1;34m(self, x, enc_output, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[0;32m     20\u001b[0m attn_output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerNorm1(x\u001b[38;5;241m+\u001b[39mattn_output1)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# print(f\"decoder input into second multihead attention layer:{attn_output1.shape}\")\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m attn_output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiHAttention2\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattn_output1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m attn_output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerNorm2(attn_output2\u001b[38;5;241m+\u001b[39mattn_output1)\n\u001b[0;32m     25\u001b[0m Feedforward_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFeedForwardNN(attn_output2)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[97], line 74\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, v, k, q, mask)\u001b[0m\n\u001b[0;32m     68\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_embedding_perHead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWv(v))\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# print(\"v shape after splitting\", v.shape)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(\"q shape after splitting\", q.shape)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# print(\"k shape after splitting\", k.shape)\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m attention,atten_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m attention \u001b[38;5;241m=\u001b[39m attention\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m     76\u001b[0m attention \u001b[38;5;241m=\u001b[39m attention\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_models)\n",
      "Cell \u001b[1;32mIn[97], line 48\u001b[0m, in \u001b[0;36mMultiHeadAttention.cal_attention\u001b[1;34m(self, q, k, v, mask)\u001b[0m\n\u001b[0;32m     46\u001b[0m     attention \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (mask\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e9\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# print(\"attention values after masking\", attention[0,0,:,:])\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# should be applied along the sequence which is the 3rd dimension\u001b[39;00m\n\u001b[0;32m     49\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attention_weights, v)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# print(\"mask\", mask[0,0,:,:])\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# print(\"q shape\", q.shape)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# print(\"mask shape\", mask.shape)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# print(\"attention weights shape\", attention_weights.shape)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# print(\"attention weights example\", attention_weights[0,0,:,:])\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = real != 0\n",
    "    print(real.shape)\n",
    "    # print(f\"real shape: {real.shape}\")\n",
    "    # probabilities\n",
    "    # probabilities = F.softmax(pred, dim=-1)\n",
    "    # predicted_tokens = torch.argmax(probabilities, dim=-1)\n",
    "    # print(predicted_tokens[0,:])\n",
    "\n",
    "  \n",
    "    loss = nn.CrossEntropyLoss(reduction='none')(pred.transpose(1, 2), real)\n",
    "    # this crossentropyloss does both the softmax classication and the loss calculation\n",
    "    # print(\"loss shape\",loss.shape)\n",
    "    # print(\"loss:\", loss)\n",
    "\n",
    "    mask = mask.float()\n",
    "    # print(\"mask\",mask)\n",
    "    # print(\"loss matrix shape\", loss.shape)\n",
    "    # print(\"loss before mask\",loss)\n",
    "    loss *= mask\n",
    "    # print(\"loss after mask\", loss)\n",
    "\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def train_model(transformer, train_loader, num_epochs, learning_rate, model_name, pretrained):\n",
    "\n",
    "    # loading pretrained models where available\n",
    "    if pretrained:\n",
    "        transformer.load_state_dict(torch.load(model_name))\n",
    "    optimizer = optim.Adam(transformer.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        transformer.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for idx_num, (properties, smiles) in enumerate(train_loader):\n",
    "   \n",
    "            # print(\"properties: \", properties.shape)\n",
    "            # print(\"smiles\", smiles.shape)\n",
    "            # print(\"smiles example\", smiles[0,:])\n",
    "            properties = properties.to(device)\n",
    "            smiles = smiles.to(device)\n",
    "            # print(\"target: \",smiles.shape)\n",
    "            # print(\"properties:\", properties.shape)\n",
    "            # print(\"smiles before masking: \",smiles)\n",
    "            \n",
    "            # print(\"smiles after masking\", enc_padding_mask)\n",
    "            # print(\"look ahead dimension:\", smiles.size(1))\n",
    "            look_ahead_mask = create_look_ahead_mask(smiles.size(1))\n",
    "            dec_padding_mask = create_padding_mask(smiles)\n",
    "\n",
    "            # print(\"look ahead mask shape\", look_ahead_mask.shape)\n",
    "            # print(\"padding mask shape\", dec_padding_mask.shape)\n",
    "            # print(\"look ahead mask: \", look_ahead_mask)\n",
    "            # print(\"padding mask\", dec_padding_mask)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = transformer(properties, smiles, look_ahead_mask, dec_padding_mask, training=True)\n",
    "            # print(\"predictions\", predictions.shape)\n",
    "            # print(\"smiles: \", smiles.shape)\n",
    "            loss = loss_function(smiles[:, 1:], predictions[:, :-1])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            print(\"batch loss\", loss.item())\n",
    "            # save model at the end of each epoch\n",
    "            torch.save(transformer.state_dict(), model_name)\n",
    "            \n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / (idx_num + 1)}')\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "target_vocab_size = len(char_to_idx)\n",
    "print(\"target vocab size\", target_vocab_size)\n",
    "num_layers = 8\n",
    "enc_d_model = 5 # number of properties\n",
    "dec_d_model = 128\n",
    "enc_num_heads = 1\n",
    "dec_num_heads = 8\n",
    "enc_dff = 128 # dimension of the feed forward layer\n",
    "dec_dff = enc_dff\n",
    "pe_target = 1000 # positional encoding\n",
    "model_name = \"molecularTransformer2.pth\"\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 20\n",
    "pretrained = False\n",
    "\n",
    "transformer = Transformer(num_layers, enc_d_model, dec_d_model,\n",
    "                          enc_num_heads, dec_num_heads, enc_dff, \n",
    "                          dec_dff, target_vocab_size, pe_target)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer = transformer.to(device)\n",
    "\n",
    "# Train the model\n",
    "train_model(transformer, train_loader, num_epochs, learning_rate, model_name, pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SMILES: <start>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "actual smiles: <start>COC(=O)C1=C2CCC(C2=C(C=C1)Br)OC(=O)C(F)(F)F<end>\n",
      "Generated SMILES: <start>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "actual smiles: <start>CCN1C=C(C=N1)OC2=C(C=CC(=C2)S(=O)(=O)N(C)C)N<end>\n",
      "Generated SMILES: <start>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "actual smiles: <start>CC(C)(C)C1=CN=C(C=C1)OC2=C(C(=CC=C2)Cl)CN<end>\n",
      "Generated SMILES: <start>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "actual smiles: <start>CC(C)OC1=NC=C(C=C1)CNC(=O)C2=CN=C(C=C2)OCCOC(C)(C)C<end>\n",
      "Generated SMILES: <start>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "actual smiles: <start>CCCCNC(=O)/C(=N/OS(=O)(=O)C1=CC=C(C=C1)C)/C#N<end>\n",
      "Generated SMILES: <start>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "actual smiles: <start>COC1=NC(=NC(=N1)O[C@H]2[C@@H]([C@H]([C@@H]([C@H](O2)CO[C@@H]3[C@@H]([C@H]([C@H]([C@H](O3)CO)O)O)O)O)O)O)OC<end>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m end_token_idx \u001b[38;5;241m=\u001b[39m char_to_idx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<end>\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Perform inference on the test dataset\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[43minfer_and_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_token_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_token_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_to_char\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[74], line 64\u001b[0m, in \u001b[0;36minfer_and_print\u001b[1;34m(transformer, test_loader, max_length, start_token_idx, end_token_idx, idx_to_char)\u001b[0m\n\u001b[0;32m     61\u001b[0m properties \u001b[38;5;241m=\u001b[39m properties\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Perform greedy decoding\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_token_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_token_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Convert the generated token indices to SMILES characters\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# print(generated_sequence.shape)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# print(smiles.shape)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m generated_smiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([idx_to_char[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m generated_sequence \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idx_to_char \u001b[38;5;129;01mand\u001b[39;00m idx \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[74], line 29\u001b[0m, in \u001b[0;36mgreedy_decode\u001b[1;34m(transformer, properties, max_length, start_token_idx, end_token_idx)\u001b[0m\n\u001b[0;32m     24\u001b[0m dec_padding_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# No padding required during inference\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Pass through the model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# print(\"properties\", properties.shape)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# print(\"output sequence\", output_sequence.shape)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# print(\"predictions\",predictions.shape)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# print(\"starting tokens:\", output_sequence)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# print(\"predictions\", predictions)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Get the predicted token for the last position\u001b[39;00m\n\u001b[0;32m     34\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# Focus on the last token in the sequence\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[61], line 28\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, properties, target, look_ahead_mask, dec_padding_mask, training)\u001b[0m\n\u001b[0;32m     25\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder output reshaped: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menc_output_reshaped\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDECODER STARTED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m ffl_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(dec_output)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#####during training:\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, enc_output, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding[:, :seq_len, :]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m---> 33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal decoder output shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[1;34m(self, x, enc_output, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[0;32m     19\u001b[0m attn_output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerNorm1(x\u001b[38;5;241m+\u001b[39mattn_output1)\n\u001b[0;32m     20\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder input into second multihead attention layer:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_output1\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m attn_output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiHAttention2\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattn_output1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m attn_output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerNorm2(attn_output2\u001b[38;5;241m+\u001b[39mattn_output1)\n\u001b[0;32m     24\u001b[0m Feedforward_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFeedForwardNN(attn_output2)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, v, k, q, mask)\u001b[0m\n\u001b[0;32m     49\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_embedding_perHead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWq(q))\n\u001b[0;32m     50\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_embedding_perHead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWk(k))\n\u001b[1;32m---> 51\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_embedding_perHead(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     53\u001b[0m attention,atten_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcal_attention(q,k,v,mask)\n\u001b[0;32m     54\u001b[0m attention \u001b[38;5;241m=\u001b[39m attention\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def greedy_decode(transformer, properties, max_length, start_token_idx, end_token_idx):\n",
    "    \"\"\"\n",
    "    Perform greedy decoding on the Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        transformer: The trained Transformer model.\n",
    "        properties: The input physical properties (features).\n",
    "        max_length: The maximum length of the sequence to generate.\n",
    "        start_token_idx: The index of the start token in the vocabulary.\n",
    "        end_token_idx: The index of the end token in the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        A list of generated token indices representing the predicted sequence.\n",
    "    \"\"\"\n",
    "    # Initialize the output sequence with the start token\n",
    "    output_sequence = torch.tensor([[start_token_idx]], dtype=torch.long).to(device)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Create masks\n",
    "        look_ahead_mask = create_look_ahead_mask(output_sequence.size(1))\n",
    "        dec_padding_mask = None  # No padding required during inference\n",
    "\n",
    "        # Pass through the model\n",
    "        # print(\"properties\", properties.shape)\n",
    "        # print(\"output sequence\", output_sequence.shape)\n",
    "        predictions = transformer(properties, output_sequence, look_ahead_mask, dec_padding_mask, training=False)\n",
    "        # print(\"predictions\",predictions.shape)\n",
    "        # print(\"starting tokens:\", output_sequence)\n",
    "        # print(\"predictions\", predictions)\n",
    "        # Get the predicted token for the last position\n",
    "        predictions = predictions[:, -1:]  # Focus on the last token in the sequence\n",
    "\n",
    "        # Concatenate the predicted token to the output sequence\n",
    "        output_sequence = torch.cat([output_sequence, predictions], dim=-1)\n",
    "\n",
    "        # Stop if the end token is predicted\n",
    "        if predictions.item() == end_token_idx:\n",
    "            break\n",
    "\n",
    "    return output_sequence.squeeze().tolist()\n",
    "\n",
    "def infer_and_print(transformer, test_loader, max_length, start_token_idx, end_token_idx, idx_to_char):\n",
    "    \"\"\"\n",
    "    Perform inference on the test dataset and print the generated sequences.\n",
    "    \n",
    "    Args:\n",
    "        transformer: The trained Transformer model.\n",
    "        test_loader: DataLoader containing the test data (properties).\n",
    "        max_length: The maximum sequence length for generation.\n",
    "        start_token_idx: The index of the start token.\n",
    "        end_token_idx: The index of the end token.\n",
    "        idx_to_char: Dictionary to convert indices back to SMILES characters.\n",
    "    \"\"\"\n",
    "    transformer.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_num, (properties,smiles) in enumerate(test_loader):\n",
    "            properties = properties.to(device)\n",
    "\n",
    "            # Perform greedy decoding\n",
    "            generated_sequence = greedy_decode(transformer, properties, max_length, start_token_idx, end_token_idx)\n",
    "\n",
    "            # Convert the generated token indices to SMILES characters\n",
    "            # print(generated_sequence.shape)\n",
    "            # print(smiles.shape)\n",
    "\n",
    "            generated_smiles = ''.join([idx_to_char[idx] for idx in generated_sequence if idx in idx_to_char and idx != 0])\n",
    "            smiles = list(smiles[0,:])\n",
    "            smiles = np.array(smiles)\n",
    "            # print(smiles)\n",
    "            actual_smiles = ''.join([idx_to_char[idx] for idx in smiles if idx in idx_to_char and idx != 0])\n",
    "            print(f\"Generated SMILES: {generated_smiles}\")\n",
    "            print(\"actual smiles:\", actual_smiles)\n",
    "\n",
    "# Load the trained model\n",
    "transformer.load_state_dict(torch.load(model_name))\n",
    "\n",
    "# Set up parameters for inference\n",
    "max_length =  288 # Maximum sequence length for SMILES generation\n",
    "start_token_idx = char_to_idx['<start>']\n",
    "end_token_idx = char_to_idx['<end>']\n",
    "\n",
    "# Perform inference on the test dataset\n",
    "infer_and_print(transformer, test_loader, max_length, start_token_idx, end_token_idx, idx_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
