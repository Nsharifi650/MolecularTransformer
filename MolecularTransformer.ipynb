{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 11:23:50 - This is a debug message - Line: 16\n",
      "2024-08-10 11:23:50 - This is an info message - Line: 17\n",
      "2024-08-10 11:23:50 - This is a warning message - Line: 18\n",
      "2024-08-10 11:23:50 - This is an error message - Line: 19\n",
      "2024-08-10 11:23:50 - This is a critical message - Line: 20\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "file_handler = logging.FileHandler('Logs.log')\n",
    "console_handler = logging.StreamHandler()\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s - Line: %(lineno)d', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "logger.debug(\"This is a debug message\")\n",
    "logger.info(\"This is an info message\")\n",
    "logger.warning(\"This is a warning message\")\n",
    "logger.error(\"This is an error message\")\n",
    "logger.critical(\"This is a critical message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'by' from 'selenium.webdriver.common.by' (c:\\Users\\NajibS\\.conda\\envs\\RAG_env\\Lib\\site-packages\\selenium\\webdriver\\common\\by.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Options\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m by\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'by' from 'selenium.webdriver.common.by' (c:\\Users\\NajibS\\.conda\\envs\\RAG_env\\Lib\\site-packages\\selenium\\webdriver\\common\\by.py)"
     ]
    }
   ],
   "source": [
    "######### a new method that could work on heroku\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import by\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from crewai import Agent, Task\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "class BrowserTools:\n",
    "    @tool(\"Scrape website content\")\n",
    "    def scrape_and_summarize_website(website):\n",
    "        \"\"\"Useful to scrape and summarize a website content\"\"\"\n",
    "\n",
    "        # Set up Selenium with headless Chrome\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(website)\n",
    "\n",
    "        # Extract content with BeautifulSoup or any other method\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        content = soup.get_text()\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        # Further processing and summarization as needed\n",
    "        content = [content[i:i + 8000] for i in range(0, len(content), 8000)]\n",
    "\n",
    "        summaries = []\n",
    "        for chunk in content:\n",
    "            agent = Agent(\n",
    "                role='Principal Researcher',\n",
    "                goal='Do amazing research and summaries based on the content you are working with',\n",
    "                backstory=\"You're a Principal Researcher at a big company and you need to do research about a given topic.\",\n",
    "                allow_delegation=False)\n",
    "\n",
    "            task = Task(\n",
    "                agent=agent,\n",
    "                description=f'Analyze and summarize the content below, make sure to include the most relevant information in the summary, return only the summary nothing else.\\n\\nCONTENT\\n----------\\n{chunk}',\n",
    "                expected_output='A summarized report of the content provided.'\n",
    "            )\n",
    "\n",
    "            summary = task.execute()\n",
    "            summaries.append(summary)\n",
    "\n",
    "        return \"\\n\\n\".join(summaries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIHEAD ATTENTION \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        try:\n",
    "            assert d_model % num_heads == 0\n",
    "        except Exception as e:\n",
    "            logger.error(\"dimension of the embedding model is not divisable by number of heads\")\n",
    "        \n",
    "        self.d_models = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # The query, key, value learnable matrices\n",
    "        self.Wq = nn.Linear(d_model, d_model)\n",
    "        self.Wk = nn.Linear(d_model, d_model)\n",
    "        self.Wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.FCLayer = nn.Linear(d_model, d_model)\n",
    "    def split_embedding_perHead(self,x):\n",
    "        # x shape is (batch_size, seq_len, d_model)\n",
    "        (batch_size, seq_len, d_model) = x.shape\n",
    "        # logger.info(f\"multi-head; x-shape: {x.shape}\")\n",
    "        # let's reshape to (batch_size, seq_len, num_heads, depth)\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        logger.info(f\"Multi-head; x reshaped: {x.shape} \")\n",
    "        # changing the dimensions order to:(batch_size, num_heads, seq_len, depth)\n",
    "        x = x.permute(0,2,1,3)\n",
    "        return x\n",
    "    \n",
    "    def cal_attention(self,q,k,v,mask):\n",
    "        qk = torch.matmul(q, k.permute(0,1,3,2))\n",
    "        dk=torch.tensor(k.shape[-1], dtype=torch.float32)\n",
    "        #dk is a tensor scalar!\n",
    "        attention = qk/torch.sqrt(dk)\n",
    "        if mask is not None:\n",
    "            attention += (mask*-1e9)\n",
    "        attention_weights = F.softmax(attention, dim=1)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def forward(self, v,k,q,mask):\n",
    "        batch_size = q.shape[0]\n",
    "        q = self.split_embedding_perHead(self.Wq(q))\n",
    "        k = self.split_embedding_perHead(self.Wk(k))\n",
    "        v = self.split_embedding_perHead(self.Wv(v))\n",
    "\n",
    "        attention,atten_weights = self.cal_attention(q,k,v,mask)\n",
    "        attention = attention.permute(0,2,1,3).contiguous()\n",
    "        attention = attention.reshape(batch_size, -1, self.d_models)\n",
    "\n",
    "        output = self.FCLayer(attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ENCODER LAYER\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model, num_heads,dff):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.MultiHAttention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.FeedForwardNN = nn.Sequential(\n",
    "            nn.Linear(d_model,dff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dff,d_model)\n",
    "\n",
    "        )\n",
    "        self.layerNorm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.layerNorm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "    def forward(self,x,mask):\n",
    "        # logger.info(\"multihead encoder initated\")\n",
    "        attn_output = self.MultiHAttention(x,x,x,mask)\n",
    "        output1 = self.layerNorm1(x+attn_output)\n",
    "        output2 = self.FeedForwardNN(output1)\n",
    "        output3 = self.layerNorm2(output1+ output2)\n",
    "        return output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE DECODER LAYER\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model, num_heads, dff):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.MultiHAttention1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.MultiHAttention2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.FeedForwardNN = nn.Sequential(\n",
    "            nn.Linear(d_model,dff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dff,d_model)\n",
    "\n",
    "        )\n",
    "        self.layerNorm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.layerNorm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.layerNorm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn_output1 = self.MultiHAttention1(x,x,x,look_ahead_mask)\n",
    "        attn_output1 = self.layerNorm1(x+attn_output1)\n",
    "        logger.info(f\"decoder input into second multihead attention layer:{attn_output1.shape}\")\n",
    "        attn_output2 = self.MultiHAttention2(enc_output, enc_output,attn_output1, padding_mask)\n",
    "        attn_output2 = self.layerNorm2(attn_output2+attn_output1)\n",
    "\n",
    "        Feedforward_output = self.FeedForwardNN(attn_output2)\n",
    "        final_output = self.layerNorm3(attn_output2+Feedforward_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ENCODER AND DECODER\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        # self.embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        # self.pos_encoding = self.positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.enc_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, dff) for _ in range(num_layers)])\n",
    "\n",
    "    # def positional_encoding(self, position, d_model):\n",
    "    #     angle_rads = self.get_angles(np.arange(position)[:,np.newaxis], np.arange(d_model)[np.newaxis,:], d_model)\n",
    "    #     angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    #     angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    #     pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    #     return torch.tensor(pos_encoding, dtype=torch.float32)\n",
    "    \n",
    "    # def get_angles(self, pos, i, d_model):\n",
    "    #     angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    #     return pos * angle_rates\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # the multihead attention class will require x to be of shape\n",
    "        # batch, seq, d_model but for properties, there is no sequence so\n",
    "        # will add an additional dimension of length 1 for seq\n",
    "        x = x.unsqueeze(1) \n",
    "        logger.info(f\"embedding input type: {type(x)}\")\n",
    "        logger.info(f\"embedding input shape: {x.shape}\")\n",
    "        # x += self.pos_encoding[:, :seq_len, :]\n",
    "        logger.info(\"encoder layer initiated\")\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, mask=None)\n",
    "\n",
    "        logger.info(\"encoder layer done\")\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(target_vocab_size, d_model) # d_model is the size of embedding vector\n",
    "        self.pos_encoding = self.positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, dff) for _ in range(num_layers)])\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return torch.tensor(pos_encoding, dtype=torch.float32)\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(1000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        logger.info(f\"decoder input shape to the embedding: {x.shape}\")\n",
    "        seq_len = x.size(1)\n",
    "        x = self.embedding(x)\n",
    "        logger.info(f\"decoder input shape after embedding: {x.shape}\")\n",
    "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMER\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,num_layers, enc_d_model, dec_d_model,\n",
    "                enc_num_heads, dec_num_heads, enc_dff, \n",
    "                dec_dff, target_vocab_size, pe_target):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
    "        self.encoder = Encoder(num_layers, enc_d_model, enc_num_heads, enc_dff)\n",
    "        self.decoder = Decoder(num_layers, dec_d_model, dec_num_heads, dec_dff, target_vocab_size, pe_target)\n",
    "        self.final_layer = nn.Linear(dec_d_model, target_vocab_size)\n",
    "\n",
    "    def forward(self, properties, target, look_ahead_mask, dec_padding_mask):\n",
    "        logger.info(\"ENCODER STARTED\")\n",
    "        enc_output = self.encoder(properties)\n",
    "        logger.info(\"ENCODER COMPLETED\")\n",
    "        logger.info(f\"encoder output dimensions:{enc_output.shape}\")\n",
    "        logger.info(\"DECODER STARTED\")\n",
    "        dec_output = self.decoder(target, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of smiles:  (5837,)\n",
      "{'#': 1, '%': 2, '(': 3, ')': 4, '+': 5, '-': 6, '.': 7, '/': 8, '0': 9, '1': 10, '2': 11, '3': 12, '4': 13, '5': 14, '6': 15, '7': 16, '8': 17, '9': 18, '=': 19, '@': 20, 'A': 21, 'B': 22, 'C': 23, 'F': 24, 'G': 25, 'H': 26, 'I': 27, 'K': 28, 'L': 29, 'M': 30, 'N': 31, 'O': 32, 'P': 33, 'R': 34, 'S': 35, 'T': 36, 'U': 37, 'V': 38, 'W': 39, 'Y': 40, 'Z': 41, '[': 42, '\\\\': 43, ']': 44, 'a': 45, 'b': 46, 'c': 47, 'd': 48, 'e': 49, 'f': 50, 'g': 51, 'h': 52, 'i': 53, 'l': 54, 'm': 55, 'n': 56, 'o': 57, 'p': 58, 'r': 59, 's': 60, 't': 61, 'u': 62}\n",
      "max smiles length:  426\n",
      "smiles length: 5837\n",
      "smiles example:  [23, 23, 3, 23, 31, 4, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "smiles example length:  426\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, properties, smiles):\n",
    "        self.properties = properties\n",
    "        self.smiles = smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.properties)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.properties[idx], dtype=torch.float32), torch.tensor(self.smiles[idx], dtype=torch.long)\n",
    "\n",
    "\n",
    "def preprocess_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    properties = data[['polararea', 'complexity', 'heavycnt', 'hbonddonor', 'hbondacc']].values\n",
    "    smiles = data['isosmiles'].values\n",
    "    print(\"length of smiles: \", smiles.shape)\n",
    "    # print(f\"smiles: {smiles}\")\n",
    "\n",
    "    # print(f\"properties: {properties}\")\n",
    "    \n",
    "    # Normalize properties\n",
    "    scaler = StandardScaler()\n",
    "    properties = scaler.fit_transform(properties)\n",
    "    \n",
    "    # Convert SMILES to a list of character indices\n",
    "    # only unique characters remain\n",
    "    # this is for creating a vocab to use to enumerate the smiles notation\n",
    "    char_to_idx = {char: idx + 1 for idx, char in enumerate(sorted(set(''.join(smiles))))}\n",
    "\n",
    "    print(char_to_idx)\n",
    "    # reversing the index to character\n",
    "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "    \n",
    "    max_smiles_len = max(len(s) for s in smiles)\n",
    "    print(\"max smiles length: \", max_smiles_len)\n",
    "    smiles_indices = [[char_to_idx[char] for char in smi] + [0] * (max_smiles_len - len(smi)) for smi in smiles]\n",
    "\n",
    "    # testing the smiles indices code\n",
    "    print(\"smiles length:\",len(smiles_indices))\n",
    "    for smile_i in smiles_indices:\n",
    "        print(\"smiles example: \", smile_i)\n",
    "        print(\"smiles example length: \", len(smile_i))\n",
    "        break\n",
    "\n",
    "    return properties, smiles_indices, char_to_idx, idx_to_char, scaler\n",
    "\n",
    "properties, smiles_indices, char_to_idx, idx_to_char, scaler = preprocess_data('pubchem.csv')\n",
    "\n",
    "train_props, test_props, train_smiles, test_smiles = train_test_split(properties, smiles_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = MoleculeDataset(train_props, train_smiles)\n",
    "test_dataset = MoleculeDataset(test_props, test_smiles)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq_masked = torch.tensor(seq) == 0 # True if value is 0 otherwise false\n",
    "    return seq_masked.unsqueeze(1).unsqueeze(2) \n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    # creating an upper triangle of 1s\n",
    "    mask = torch.triu(torch.ones((size, size)), diagonal=1) \n",
    "    return mask.unsqueeze(0).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NajibS\\AppData\\Local\\Temp\\ipykernel_4604\\2541678855.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seq_masked = torch.tensor(seq) == 0 # True if value is 0 otherwise false\n",
      "2024-08-12 10:00:05 - ENCODER STARTED - Line: 15\n",
      "2024-08-12 10:00:05 - embedding input type: <class 'torch.Tensor'> - Line: 27\n",
      "2024-08-12 10:00:05 - embedding input shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - encoder layer initiated - Line: 30\n",
      "2024-08-12 10:00:05 - multihead encoder initated - Line: 15\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multihead encoder initated - Line: 15\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multihead encoder initated - Line: 15\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multihead encoder initated - Line: 15\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 1, 5]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 1, 1, 5])  - Line: 31\n",
      "2024-08-12 10:00:05 - encoder layer done - Line: 34\n",
      "2024-08-12 10:00:05 - ENCODER COMPLETED - Line: 17\n",
      "2024-08-12 10:00:05 - encoder output dimensions:torch.Size([32, 1, 5]) - Line: 18\n",
      "2024-08-12 10:00:05 - DECODER STARTED - Line: 19\n",
      "2024-08-12 10:00:05 - decoder input shape to the embedding: torch.Size([32, 426]) - Line: 62\n",
      "2024-08-12 10:00:05 - decoder input shape after embedding: torch.Size([32, 426, 128]) - Line: 65\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 426, 128]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 426, 8, 16])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 426, 128]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 426, 8, 16])  - Line: 31\n",
      "2024-08-12 10:00:05 - multi-head; x-shape: torch.Size([32, 426, 128]) - Line: 28\n",
      "2024-08-12 10:00:05 - Multi-head; x reshaped: torch.Size([32, 426, 8, 16])  - Line: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "properties:  torch.Size([32, 5])\n",
      "smiles torch.Size([32, 426])\n",
      "look ahead dimension: 426\n",
      "multihead done\n",
      "multihead done\n",
      "multihead done\n",
      "multihead done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 10:00:06 - decoder input into second multihead attention layer:torch.Size([32, 426, 128]) - Line: 20\n",
      "2024-08-12 10:00:06 - multi-head; x-shape: torch.Size([32, 426, 128]) - Line: 28\n",
      "2024-08-12 10:00:06 - Multi-head; x reshaped: torch.Size([32, 426, 8, 16])  - Line: 31\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x5 and 128x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m transformer \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[105], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(transformer, train_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     33\u001b[0m dec_padding_mask \u001b[38;5;241m=\u001b[39m create_padding_mask(smiles)\n\u001b[0;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 36\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(smiles[:, \u001b[38;5;241m1\u001b[39m:], predictions[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[102], line 20\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, properties, target, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[0;32m     18\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder output dimensions:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menc_output\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDECODER STARTED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(dec_output)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[101], line 70\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, enc_output, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[0;32m     67\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding[:, :seq_len, :]\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m---> 70\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[100], line 21\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[1;34m(self, x, enc_output, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[0;32m     19\u001b[0m attn_output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerNorm1(x\u001b[38;5;241m+\u001b[39mattn_output1)\n\u001b[0;32m     20\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder input into second multihead attention layer:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_output1\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m attn_output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiHAttention2\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattn_output1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m attn_output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerNorm2(attn_output2\u001b[38;5;241m+\u001b[39mattn_output1)\n\u001b[0;32m     24\u001b[0m Feedforward_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFeedForwardNN(attn_output2)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 50\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, v, k, q, mask)\u001b[0m\n\u001b[0;32m     48\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     49\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_embedding_perHead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWq(q))\n\u001b[1;32m---> 50\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_embedding_perHead(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     51\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_embedding_perHead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWv(v))\n\u001b[0;32m     53\u001b[0m attention,atten_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcal_attention(q,k,v,mask)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x5 and 128x128)"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = real != 0\n",
    "    loss_ = nn.CrossEntropyLoss()(pred.transpose(1, 2), real)\n",
    "    \n",
    "    mask = mask.float()\n",
    "    loss_ *= mask\n",
    "\n",
    "    return torch.mean(loss_)\n",
    "\n",
    "def train_model(transformer, train_loader, num_epochs, learning_rate):\n",
    "    optimizer = optim.Adam(transformer.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        transformer.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for idx_num, (properties, smiles) in enumerate(train_loader):\n",
    "   \n",
    "            print(\"properties: \", properties.shape)\n",
    "            print(\"smiles\", smiles.shape)\n",
    "            properties = properties.to(device)\n",
    "            smiles = smiles.to(device)\n",
    "            # print(\"target: \",smiles.shape)\n",
    "            # print(\"input:\", smiles.shape)\n",
    "            # print(\"smiles before masking: \",smiles)\n",
    "            \n",
    "            # print(\"smiles after masking\", enc_padding_mask)\n",
    "            print(\"look ahead dimension:\", smiles.size(1))\n",
    "            look_ahead_mask = create_look_ahead_mask(smiles.size(1))\n",
    "            dec_padding_mask = create_padding_mask(smiles)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = transformer(properties, smiles, look_ahead_mask, dec_padding_mask)\n",
    "            loss = loss_function(smiles[:, 1:], predictions[:, :-1])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / (idx_num + 1)}')\n",
    "\n",
    "# Initialize the model\n",
    "target_vocab_size = len(char_to_idx) + 1  # +1 for padding token\n",
    "num_layers = 4\n",
    "enc_d_model = 128 # number of properties\n",
    "dec_d_model = 128\n",
    "enc_num_heads = 1\n",
    "dec_num_heads = 8\n",
    "enc_dff = 128 # dimension of the feed forward layer\n",
    "dec_dff = 128 \n",
    "pe_target = 1000 # positional encoding\n",
    "\n",
    "transformer = Transformer(num_layers, enc_d_model, dec_d_model,\n",
    "                          enc_num_heads, dec_num_heads, enc_dff, \n",
    "                          dec_dff, target_vocab_size, pe_target)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer = transformer.to(device)\n",
    "\n",
    "# Train the model\n",
    "train_model(transformer, train_loader, num_epochs=20, learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
